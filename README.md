# stereotypes
This NLP project examines the prevalence of stereotypes about Hazaras and other targets in user comments on YouTube videos. 
Since 2021, the movement to recognise the violence against this ethnic and religious minority group as  genocide has gained momentum, and more content by and about Hazaras is available in social media and news outlets.

NLP makes it possible to analyse sentiment in text and detect bias. NLP models that are trained on vast datasets  can be trained to recognise certain patterns of language, such as biased speech and stereotypes.
Research has shown how racial, gender and affective stereotypes can be detected using NLP. 
Newer methods include word embeddings and BERT.  

**CW:** This project contains examples of offensive and prejudicial comments aimed at ethnic groups and religions. They do not in any way reflect my views. Please read with care. 

Data available upon request. 
